<!DOCTYPE html>
<html lang="fr">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>EmotionAI-voice | LONDE  Tristan</title>
    <meta name="author" content="LONDE  Tristan">
    <meta name="description" content="An AI-powered application for detecting human emotions">
    <meta name="keywords" content="portfolio, projets, tristanlonde, franÃ§ais, ia, ai">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/favicon.jpg">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://tirovo.github.io//projects/EmotionAI-voice/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header --><header>
    <!-- Nav Bar -->
    <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
            <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">LONDEÂ </span>Tristan</a>
            <!-- Navbar Toggle -->
            <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar top-bar"></span>
                <span class="icon-bar middle-bar"></span>
                <span class="icon-bar bottom-bar"></span>
            </button>

            <div class="collapse navbar-collapse text-right" id="navbarNav">
                <ul class="navbar-nav ml-auto flex-nowrap">

                    <!-- About -->
                    <li class="nav-item ">
                        <a class="nav-link" href="/">About</a>
                    </li>
                    

                    <!-- Other pages -->
                    <li class="nav-item ">
                        <a class="nav-link" href="/projects/">Projects</a>
                    </li>
                    <li class="nav-item ">
                        <a class="nav-link" href="/resume/">Resume</a>
                    </li>

                    <!-- Toggle theme mode -->
                    <li class="toggle-container">
                        <button id="light-toggle" title="Change theme">
                            <i class="fas fa-moon"></i>
                            <i class="fas fa-sun"></i>
                        </button>
                    </li>

                    <!-- Toggle language mode -->
                    <li class="nav-item" id="language-toggle">
                        <a class="nav-link" id="to-fr" href="https://translate.google.com/translate?hl=fr&amp;sl=en&amp;u=https://mpek29.github.io" style="padding-bottom: 0.4rem;padding-top: 0.4rem;padding-right: 0px;" rel="external nofollow noopener" target="_blank">
                            <img alt="FR" title="FR" src="https://mpek29.github.io/assets/img/languages/fr.gif" style="padding-left: 6px;padding-right: 0px;">
                        </a>
                    </li>

                </ul>
            </div>
        </div>
    </nav>

    
    <!-- Scrolling Progress Bar -->
    <progress id="progress" value="0">
        <div class="progress-container">
            <span class="progress-bar"></span>
        </div>
    </progress>
</header>

<script>
    // VÃ©rifie si l'utilisateur est sur Google Traduction
    const urlPattern = /^https:\/\/tirovo-github-io\.translate\.goog.*\?_x_tr_sl=en&_x_tr_tl=fr&_x_tr_hl=fr$/;
    if (urlPattern.test(window.location.href)) {
        // Remplace le bouton par le bouton anglais
        const languageToggle = document.getElementById('language-toggle');
        languageToggle.innerHTML = `
            <a class="nav-link" href="https://tirovo.github.io/" style="padding-bottom: 0.4rem;padding-top: 0.4rem;padding-right: 0px;">
                <img alt="EN" title="EN" src="https://tirovo.github.io/assets/img/languages/en.gif" style="padding-left: 6px;padding-right: 0px;">
            </a>
        `;
    }
</script>


    <!-- Content -->
    <div class="container mt-5">
      <!-- page.html -->
        <div class="post">
          <header class="post-header">
            <h1 class="post-title">EmotionAI-voice
              
              
              
              
              <a href="https://github.com/Tirovo/EmotionAI-voice" target="_blank" rel="noopener noreferrer" class="float-right"><i class="fab fa-github" style="margin-left: 10px;margin-right: 10px;"></i></a>
              

              

              

            </h1>
            <p class="post-description">An AI-powered application for detecting human emotions</p>
          </header>

          <article>
            <p><strong>EmotionAI Voice</strong> is an open-source deep learning project that classifies vocal emotions using raw <code class="language-plaintext highlighter-rouge">.wav</code> audio.<br>
Itâ€™s designed for applications in mental health monitoring, UX analysis, and intelligent speech interfaces.</p>

<p>ğŸ”¬ The model is trained <strong>from scratch</strong>, using spectrogram-based audio features, and aims to recognize 8 core emotions.</p>

<hr>

<h2 id="-features">ğŸ¯ Features</h2>

<ul>
  <li>ğŸ§  Emotion recognition: <code class="language-plaintext highlighter-rouge">neutral</code>, <code class="language-plaintext highlighter-rouge">calm</code>, <code class="language-plaintext highlighter-rouge">happy</code>, <code class="language-plaintext highlighter-rouge">sad</code>, <code class="language-plaintext highlighter-rouge">angry</code>, <code class="language-plaintext highlighter-rouge">fearful</code>, <code class="language-plaintext highlighter-rouge">disgust</code>, <code class="language-plaintext highlighter-rouge">surprised</code>
</li>
  <li>ğŸ§ Accepts <code class="language-plaintext highlighter-rouge">.wav</code> audio inputs (from RAVDESS dataset)</li>
  <li>ğŸ“Š CNN and CNN+GRU models implemented in PyTorch</li>
  <li>ğŸ” Real-time evaluation with confusion matrix and accuracy tracking</li>
  <li>ğŸ› ï¸ Fully open-source and customizable (no pre-trained models)</li>
  <li>ğŸ§ª Includes <strong>SpecAugment</strong> for data augmentation (frequency/time masking)</li>
</ul>

<hr>

<h2 id="-dataset--ravdess">ğŸ“š Dataset â€” RAVDESS</h2>

<p>We use the <a href="https://zenodo.org/record/1188976" rel="external nofollow noopener" target="_blank"><strong>RAVDESS</strong> dataset</a>, which includes:</p>

<ul>
  <li>ğŸ­ 24 professional actors (balanced male/female)</li>
  <li>ğŸ™ï¸ 1440 <code class="language-plaintext highlighter-rouge">.wav</code> files (16-bit, 48kHz)</li>
  <li>8 labeled emotions:<br>
<code class="language-plaintext highlighter-rouge">neutral</code>, <code class="language-plaintext highlighter-rouge">calm</code>, <code class="language-plaintext highlighter-rouge">happy</code>, <code class="language-plaintext highlighter-rouge">sad</code>, <code class="language-plaintext highlighter-rouge">angry</code>, <code class="language-plaintext highlighter-rouge">fearful</code>, <code class="language-plaintext highlighter-rouge">disgust</code>, <code class="language-plaintext highlighter-rouge">surprised</code>
</li>
</ul>

<p>Each <code class="language-plaintext highlighter-rouge">.wav</code> file is preprocessed into a <strong>Mel spectrogram</strong> and stored as <code class="language-plaintext highlighter-rouge">.npy</code> format.</p>

<hr>

<h2 id="-model-architectures">ğŸ§  Model Architectures</h2>

<h3 id="2-different-models">2 different models</h3>

<h4 id="-cnn-best-performance">âœ… CNN (Best Performance)</h4>

<ul>
  <li>3x Conv1D + ReLU + MaxPool</li>
  <li>Fully connected layers</li>
  <li>Dropout regularization (adjustable)</li>
</ul>

<h4 id="-cnn--gru">ğŸ” CNN + GRU</h4>

<ul>
  <li>CNN front-end for spatial encoding</li>
  <li>GRU (recurrent layers) to capture temporal dynamics</li>
  <li>Lower accuracy than CNN-only model</li>
</ul>

<hr>

<h3 id="-specaugment-data-augmentation">ğŸ§ª SpecAugment: Data Augmentation</h3>

<p>To improve generalization, we implemented <code class="language-plaintext highlighter-rouge">SpecAugmentTransform</code> which applies:</p>

<ul>
  <li>ğŸ•’ <strong>Time masking</strong>: hides random time intervals</li>
  <li>ğŸ“¡ <strong>Frequency masking</strong>: hides random mel frequency bands</li>
</ul>

<hr>

<h3 id="-training-results">ğŸ“ˆ Training Results</h3>

<ul>
  <li>Best Validation Accuracy: <strong>~49.6%</strong>
</li>
  <li>Training set: Actors 1â€“20</li>
  <li>Validation set: Actors 21â€“24</li>
</ul>

<p><strong>Confusion Matrix Example:</strong></p>

<p><img src="figures/confusion_matrix.png" alt="ConfusionMatrix" width="700"></p>

<h3 id="-key-observations">ğŸ” Key Observations:</h3>

<ul>
  <li>Surprised, calm, and disgust are the most accurately predicted emotions.</li>
  <li>Neutral, happy, and sad tend to be confused with each other, which is common due to subtle acoustic variations.</li>
  <li>The model struggles with fearful and angry in some cases â€” suggesting those may share overlapping vocal characteristics in this dataset.</li>
  <li>Emotion classes like happy and fearful are often misclassified due to variability in expression intensity among different actors.</li>
</ul>

<h5 id="-interpretation">ğŸ“ˆ Interpretation</h5>

<p>While the model captures general emotion cues, it suffers from class overlap and limited generalization. The accuracy remains significantly above random (12.5% for 8 classes), but there is still room for improvement.</p>

<hr>

<h2 id="-getting-started">ğŸš€ Getting Started</h2>

<h3 id="1-install-dependencies">1. Install dependencies</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>pip <span class="nb">install</span> <span class="nt">-r</span> requirements.txt
</code></pre></div></div>

<h3 id="2-download-dataset-from-kaggle">2. Download dataset from Kaggle</h3>

<p>Follow the instructions in the README.md located in the data folder</p>

<h3 id="3--train-the-model">3 . Train the model</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python src/train.py
</code></pre></div></div>

<h3 id="4--evaluation-the-performances-with-a-confusion-matrix">4.  Evaluation the performances with a confusion matrix</h3>

<p>```bash
python src/confusion_matrix.py</p>


          </article>

        </div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        Â© Copyright 2025 LONDE  Tristan. 
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script defer src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
